<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://theophilegervet.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://theophilegervet.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-02T15:57:23+00:00</updated><id>https://theophilegervet.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">LMs as cultural technologies, from conveying knowledge to creating it?</title><link href="https://theophilegervet.github.io/blog/2023/llms-as-cultural-technologies/" rel="alternate" type="text/html" title="LMs as cultural technologies, from conveying knowledge to creating it?"/><published>2023-10-30T00:00:00+00:00</published><updated>2023-10-30T00:00:00+00:00</updated><id>https://theophilegervet.github.io/blog/2023/llms-as-cultural-technologies</id><content type="html" xml:base="https://theophilegervet.github.io/blog/2023/llms-as-cultural-technologies/"><![CDATA[<h3 id="lms-as-cultural-technologies">LMs as cultural technologies</h3> <p>What distinguishes humans from other animals is our ability to create knowledge (<a href="https://theophilegervet.github.io/book_notes/the-beginning-of-infinity/">useful explanations of the world</a>) and <a href="https://theophilegervet.github.io/book_notes/the-secret-of-our-success/">pass it on culturally</a>. A useful perspective on current LMs is as powerful <a href="https://arxiv.org/abs/2305.07666">cultural technologies</a>, like writing, the printing press, the Internet, and language itself, that enhance cultural transmission. From this perspective, <strong>progress on LMs as cultural technologies is currently our best lever on the rate of human progress</strong>.</p> <h3 id="lms-are-becoming-the-best-way-to-access-existing-knowledge">LMs are becoming the best way to access existing knowledge</h3> <p>Until 2022, the go-to way for humans to access existing knowledge was browsing the Internet through Google search (to find relevant articles, books, StackOverflow posts, etc.). <strong>LLM-based tools like ChatGPT or Perplexity are quickly overtaking Google search. Why?</strong></p> <p>Let’s step through the answer to this question from the perspective of a researcher or a software engineer, as I can most easily speak to this from personal experience. This should apply more broadly to any other professions that require access to existing knowledge. LLM-based tools</p> <ul> <li><strong>Better understand my questions</strong> <ul> <li><strong>Understand (more of) my context</strong> (the problem I’m trying to solve, my code, my data) - I can give a lot more of this context in ChatGPT’s chat interface than I ever could in Google’s search query, although there is a lot of room for improvement, as we’ll discuss later</li> <li><strong>Enable back-and-forth conversation</strong> to refine the question</li> </ul> </li> <li><strong>Directly answer questions</strong>instead of indirectly providing links to potential answers <ul> <li><strong>Aggregate answer components</strong> from various sources - provide both a code snippet that looks like a StackOverflow answer and an explanation paragraph that looks like documentation</li> <li><strong>Adapt the answer to my specific context</strong> - provide code snippets that directly solve my problem with my specific variables instead of a link to a relevant StackOverflow answer</li> </ul> </li> </ul> <p>The only potential downside of current LLM-based tools for accessing existing knowledge is that they can hallucinate answers. In practice, this hasn’t been much of an issue in my day-to-day work with ChatGPT. Perplexity already addresses this problem by making retrieval and citations first-class citizens. But we’ll need more work in this direction.</p> <h3 id="how-can-we-make-lms-even-better-as-gateways-to-existing-knowledge">How can we make LMs even better as gateways to existing knowledge?</h3> <p>We should enable LMs to</p> <ul> <li><strong>Directly integrate with daily tools</strong> to understand user context better - read the code repository for my project on GitHub, the draft of the paper I’m writing in Overleaf, the conversations with my collaborators on Slack, the learning curves for my training runs in WandB, etc.</li> <li><strong>Understand other modalities</strong> (images, videos, audio) as well as language - ChatGPT is already setting a high bar for images and audio, although it’s not nearly as good at image understanding as it is at text understanding yet</li> <li><strong>Synthesize</strong> large amounts of information <ul> <li><strong>Summarize</strong> large sources - an entire book or code repository from the perspective of a specific question <ul> <li>What does David Deutsch tell us about the nature of human knowledge and the place of humans in the universe in his book <a href="https://theophilegervet.github.io/book_notes/the-beginning-of-infinity/">The Beginning of Infinity</a>?</li> <li>Can you give me concrete guidelines about how to most effectively build an audience on Twitter based on the <a href="https://github.com/twitter/the-algorithm-ml">open-source algorithm</a>?</li> </ul> </li> <li><strong>Connect the dots</strong> across various sources of information, reason about commonalities and differences, provide perspective <ul> <li>From all robotics conference proceedings of the past couple of years, what are the most compelling examples of training robot policies in simulation and transferring them to real robots? What are common challenges and solutions?</li> <li>Ideally, we’d want to push this to even higher levels of abstraction: From all ML conference proceedings of the past five years and citations of these papers, what are commonalities across ideas that have had a large impact on the field? Across the ones that have been forgotten? Which lines of work have made or will make other ones obsolete?</li> </ul> </li> <li><strong>Process (much) longer input context windows</strong> to be able to ingest all this information - we should be able to take as input an entire book (100K+ words), an entire GitHub repository (1M+ tokens), all papers at a conference (40M+ tokens)</li> </ul> </li> <li><strong>Teach rather than answer</strong> - act like a personal teacher who adapts explanations to my current level of understanding, propose exercises to better master a topic</li> <li><strong>Search proactively</strong> for relevant information - proactively recommend what papers and books to read given my interests and current projects</li> <li><strong>Eliminate hallucinations</strong> - we should be able to trust the answers we get from LMs at least as much as we trust answers from credible sources via Google Search <ul> <li>We’re pretty close for simple queries that Google Search could answer, but this will become much more challenging as we move to complex synthesis of large amounts of information</li> </ul> </li> </ul> <p>The improvements above fall into two buckets:</p> <ul> <li>What can likely be done with more scale and more engineering: integrate with daily tools, understand images and videos as well as text, search proactively for relevant information</li> <li>What is likely to require new ideas: teach rather than answer, synthesize large amounts of information, eliminate hallucinations in this context</li> </ul> <h3 id="how-can-lms-create-new-knowledge">How can LMs create new knowledge?</h3> <p>To answer this question, it’s helpful to think through how humans create knowledge.</p> <p>Our best epistemology from <a href="https://www.goodreads.com/book/show/61550.The_Logic_of_Scientific_Discovery">Poppers</a>, later refined by <a href="https://theophilegervet.github.io/book_notes/the-beginning-of-infinity/">Deutsch</a>, tells us that, <strong>at the highest level of abstraction, knowledge progresses through unjustified conjectures, which are then criticized</strong>. Individual researchers conjecture new explanations of the world / solutions to problems, and the scientific community criticizes them, whether it be through a formal peer review process, by identifying a flaw in a proof, generating contradictory experimental results, deciding whether to cite a paper or not, etc. Like genetic evolution, knowledge evolves by iterative variation (new explanations / solutions to problems) and selection (criticism and experimentation).</p> <p>But concretely, what does a researcher do day-to-day? A researcher splits time between two fundamental activities:</p> <ul> <li><strong>Outer loop: problem-finding</strong> <ul> <li><strong>Learn about the field</strong>: read papers, watch talks, talk with colleagues</li> <li><strong>Synthesize the state of the field and identify promising research directions</strong> by answering questions like: What are commonalities across ideas that have had a large impact on the field or have been forgotten? Which lines of work will make other ones obsolete? What unsolved problems unlock the most important applications?</li> <li><strong>Concretize a research direction into a specific problem to solve</strong> by answering questions like: What is the simplest version of this problem that captures the essence of the idea? What is the best benchmark to convincingly demonstrate this idea to the community?</li> </ul> </li> <li><strong>Inner loop: problem-solving</strong> <ul> <li><strong>Break down a complex problem into sub-problems</strong></li> <li><strong>Conjecture a solution to a subproblem</strong>: reason by analogy to find solutions that worked for similar problems, write code to implement the solution</li> <li><strong>Run experiments to test the conjecture</strong>: write code to run the experiments, run experiments, analyze the results</li> <li>Iterate</li> </ul> </li> </ul> <p>Problem-finding is often the most challenging skill to learn. Experienced researchers excel at this outer loop, while they might get rusty at the inner loop as they progress in their careers and delegate more of it to students and collaborators.</p> <p>This outer loop is primarily about accurately synthesizing the state of existing knowledge. This should make it evident that <strong>being excellent as a gateway to existing knowledge is already flirting with creating new knowledge</strong>. This should give you pause if you dismissed LMs as imitation machines that are fundamentally unable to create new knowledge. Isn’t making it 100x easier for humans to create new knowledge already a form of creating new knowledge?</p> <p>Of course, beyond the synthesis of the state of existing knowledge, other abilities would be very handy to assist researchers in their other daily tasks:</p> <ul> <li><strong>Criticize:</strong> poke holes in an argument, offer a counter-argument, identify flaws in a proof, missing experimental data to support a claim, etc. - act like a good reviewer</li> <li><strong>Write code:</strong> implement a solution to a subproblem or the code to run experiments</li> <li><strong>Design experiments:</strong> design experiments to test a hypothesis</li> <li><strong>Analyze results:</strong> interpret experimental results and draw conclusions</li> <li><strong>Communicate results:</strong> write a paper, design a talk, write a blog post, etc.</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Theophile Gervet]]></summary></entry><entry><title type="html">Generative simulation, a paradigm towards generalist robots</title><link href="https://theophilegervet.github.io/blog/2023/generative-simulation/" rel="alternate" type="text/html" title="Generative simulation, a paradigm towards generalist robots"/><published>2023-06-25T00:00:00+00:00</published><updated>2023-06-25T00:00:00+00:00</updated><id>https://theophilegervet.github.io/blog/2023/generative-simulation</id><content type="html" xml:base="https://theophilegervet.github.io/blog/2023/generative-simulation/"><![CDATA[<h3 id="tldr">TLDR</h3> <p>Today, robots excel as specialists in structured environments, such as the robot arms employed by Amazon for picking and packaging products within warehouses. However, the true potential of robotics lies in the realm of <strong>generalist robots operating in unstructured environments</strong>. Imagine mobile robots capable of assisting the elderly with showering, dressing, maintaining a clean home, or even preparing meals. These versatile robots must possess the ability to handle diverse tasks involving unfamiliar objects within new surroundings. Achieving such broad generalization necessitates <strong>learning from large-scale and diverse data</strong>.</p> <p>In robotics, three significant data sources come into play: passive Internet data (such as YouTube videos of humans doing daily activities that robots can emulate), real-world robot experience, and simulated robot experience. In this post, we’ll go through the distinct opportunities and challenges to scale each data source and conclude that the <strong>most cost-effective approach lies in scaling simulated robot experience</strong>. We can use the magic powers of <strong>generative machine learning</strong> models trained on Internet data to simulate the wide variety of tasks we might want robots to do (e.g., cleaning a sink, cooking a pizza) in the dizzying range of environments robots will need to operate in (e.g., a house kitchen, a hospital bedroom). This can dramatically enhance the scale and diversity of simulated robot experience, unlocking the <strong>generalist robots</strong> we need. You can find details in our <a href="https://arxiv.org/abs/2305.10455">white paper</a>.</p> <h3 id="where-robots-are-today-and-where-we-want-to-take-them">Where robots are today and where we want to take them</h3> <p>The prevailing robots of today predominantly excel as specialists in structured environments. Amazon warehouse robots are a perfect example: they do a single thing really well — for example, pick up products from bins — isolated as much as possible from the rest of the world.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/generative-simulation/1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/generative-simulation/1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/generative-simulation/1-1400.webp"/> <img src="/assets/generative-simulation/1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Imagine how much more broadly robots could be used if they were able to perform any physical labor in any environment, just like ChatGPT and its future iterations will soon be able to complete increasingly complex tasks about any domain in the virtual world. They could help your grandparents take a shower and dress up in the morning, transfer patients to hospitals, clean your home, or even improvise dinner with what’s in the fridge. <strong>Most of the value of robotics will come from such generalist robots.</strong></p> <p>So why are we not there yet? Well, robotics is really hard. Robots must be able to (1) perceive the world (similar to how our brains interpret visual and tactile information), (2) understand human intentions (for example, instructions in English), and (3) translate these into physical actions using motor controls. Accomplishing this reliably across diverse tasks and environments turns out to be extremely hard. This challenge is often called <strong>Moravec’s paradox: the surprising realization that teaching machines uniquely human “high-level” abilities like abstract thought and reasoning can be relatively easier than “low-level” perception and motor control.</strong> It explains why AI is mastering games or dialogue, but robots are conspicuously missing from this revolution. According to Moravec, this can be attributed to the fact that it’s harder for us to reverse engineer our sensorimotor skills that have evolved over billions of years than our language and abstract thinking are more recent developments, less than 100,000 years old. A more modern line or argument is that we have trillions of digitized words on the web to train language understanding, while we haven’t yet been able to gather the same scale and diversity of data to train perception and motor control.</p> <h3 id="scaling-up-robotics-data-is-a-proven-path-to-get-there">Scaling up robotics data is a proven path to get there</h3> <p>The most crucial lesson learned in machine learning in recent years is the significance of <strong>broad generalization</strong>. In the realm of robotics, this refers to the ability to handle novel human intentions, involving unfamiliar objects, within new environments. <strong>The key to achieving this lies in training models on large-scale and diverse datasets.</strong> Consider the language model powering ChatGPT, which learns from the vast expanse of text available on the Internet, or the text-to-image models underlying Midjourney, which leverage hundreds of millions of captioned images.</p> <p>How can we reach this scale and diversity of data in robotics? There are three primary data sources that we can leverage: passive Internet data (such as YouTube videos showcasing human actions), real-world robot experience, and simulated robot experience. Let’s delve into the opportunities and challenges associated with scaling each of these sources.</p> <h3 id="real-world-robot-experience">Real-world robot experience</h3> <p>The most obvious source of data is real-world robot experience. There are two primary methods for teaching robots through experience. The first involves humans demonstrating tasks to the robot, typically through teleoperation, where the robot mimics the actions of expert human demonstrators. The second approach entails the robot attempting tasks independently, learning from trial and error, and focusing on the actions that yield successful outcomes.</p> <p>As you can imagine, the first approach is <strong>not very scalable</strong>. It <strong>requires a significant fleet of robots and considerable labor from human teleoperators</strong>. Google explored this approach with the Everyday Robots project, collecting around 130,000 robot demonstrations with a fleet of 13 robots over a year and a half, ultimately yielding a system capable of executing only basic pick-and-place tasks in office kitchens. The project was discontinued as part of company-wide layoffs earlier this year.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/generative-simulation/2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/generative-simulation/2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/generative-simulation/2-1400.webp"/> <img src="/assets/generative-simulation/2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The second approach of allowing robots to autonomously explore the world and discover useful behaviors has the potential to alleviate some of the human labor requirements. However, it presents its own set of challenges. Ensuring <strong>safe and efficient trial and error for robots remains an ongoing issue</strong>. You can try randomly moving your arms and legs until you find something useful without hurting yourself and see for yourself that this is hard. Additionally, this approach still demands an initial investment and continuous maintenance of a large robot fleet.</p> <p>This situation leads us to a conundrum: in order to gather sufficient real-world robot experience for training robots to perform a wide range of useful tasks, we need to deploy them at scale to users. But no user wants a robot that is not already able to do a wide enough range of useful things. This creates a classic <strong>chicken-and-egg problem</strong>, often addressed at the beginning of talks at robotics conferences.</p> <p>One potentially promising solution to overcome this challenge is to focus on <strong>training robots to excel at a small set of tasks, deploy them in real-world environments, and gather data to progressively expand their capabilities</strong>. Tesla has adopted this approach with self-driving cars, and they may soon apply it to their humanoid robot as well. This strategy requires substantial upfront investment towards building a robot fleet. It is particularly suited for use cases where there is substantial value in performing a small set of tasks exceptionally well. Tesla’s deployment of humanoid robots in factories, where there is a clear set of tasks that are valuable but not excessively difficult, aligns well with this approach.</p> <p>However, it remains <strong>uncertain whether this is the most effective path for deploying robots in homes or hospitals</strong>. These environments may demand a minimum viable set of capabilities that is more challenging to achieve without an extensive amount of training data. Starting the iterative improvement loop necessary to broaden capabilities may face greater hurdles in these contexts.</p> <h3 id="passive-internet-data">Passive Internet data</h3> <p>Our second source of data is the Internet. The Internet serves as an exceptional source of data due to its <strong>unparalleled scale</strong>: 5 billion humans using the Internet, many trillions of words written, 30,000 hours of YouTube videos uploaded every hour. We already use images on the Internet to train today’s computer vision systems and text on the Internet to train language understanding systems, deployed on robots and elsewhere. How else can we leverage Internet data for robotics?</p> <p><strong>YouTube videos, particularly those featuring human activities</strong>, hold significant value. The robotics community is exploring two primary approaches to leverage these videos: <strong>learning how humans interact with objects to accomplish daily tasks, and understanding how the world behaves</strong>, including predicting the outcomes of actions prior to execution. Let’s examine these approaches through an example.</p> <p>Imagine standing in the kitchen of your friend’s house you’re visiting for the first time. Even without taking any specific actions, you already know how to interact with most objects and can anticipate how they’ll behave as you manipulate them. For instance, you instinctively know that opening the oven involves pulling its handle downwards while opening drawers requires pulling them outward and turning on the water involves rotating the tap sideways. This intuitive grasp of physics enables you to predict that pulling the oven handle upwards will yield no results.</p> <p>Both of these capabilities are incredibly useful for robotics. Knowing how humans interact with objects to accomplish daily tasks can dramatically <strong>accelerate the trial and error process for robots</strong>, narrowing down the range of potential actions from limitless possibilities to a much smaller set of actions humans are likely to perform. The ability to anticipate outcomes of actions makes it possible to turn the question around and <strong>identify the appropriate actions to achieve desired results</strong>.</p> <p>Naturally, this approach comes with its own set of challenges. Firstly, robots possess bodies that differ from humans, <strong>necessitating adaptation</strong> to effectively interact with objects. Secondly, while Internet videos can provide a general understanding of how to interact with an oven, remember your own experience attempting tasks for the first time, such as breaking an egg without shell fragments, chopping vegetables, opening an oyster, or flipping pancakes. Even if you watched a YouTube tutorial, you probably had a hard time and needed some trial and error. The same holds for robots: fine motor control requires either very precise demonstrations via teleoperation or trial and error. Passive learning from Internet data <strong>can mitigate the need for extensive experience data and expedite its collection, but cannot remove the necessity of experience data completely</strong>.</p> <h3 id="simulated-robot-experience">Simulated robot experience</h3> <p>This brings us to our final data source: simulated robot experience. Instead of relying solely on real-world experience, can we gather experience by simulating robot interactions in virtual environments?</p> <p>To grasp the opportunities and challenges associated with this approach, let’s briefly delve into what a simulation entails. A simulator is a software tool that replicates real-world processes, such as a robot interacting with objects in its environment. It comprises <strong>two main components: physics simulation and rendering</strong>. The simulator keeps track of the states of objects within the simulated world, the physics simulation advances their states over time according to the laws of physics (e.g., accounting for gravity or collisions), and rendering generates visual representations of the world captured by sensors (e.g., the robot’s cameras).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/generative-simulation/3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/generative-simulation/3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/generative-simulation/3-1400.webp"/> <img src="/assets/generative-simulation/3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Collecting data in simulation offers several attractive advantages. First and foremost, simulators are <strong>purely software-based</strong>, which significantly reduces the frustrations and challenges associated with working with physical robot hardware. Robots are inherently slow and prone to breakdowns, making data collection in the real world a time-consuming and complex process. In contrast, data collection in simulation is <strong>orders of magnitude faster</strong> (think millions to billions of times) and <strong>more cost-effective</strong>. Instead of investing in a fleet of robots that you need to maintain over time, you can rent GPUs to run your simulations from cloud providers.</p> <p>Furthermore, investing in simulation allows for <strong>reusability across iterations of a robot’s design and even across different robots</strong>. Once a simulated world is built, making modifications to a robot’s sensors, end-effectors, or even introducing an entirely new robot can be achieved with just a few lines of code. On the other hand, in the real world, significant changes to a robot’s hardware or design would render the painstakingly collected real-world data much less useful, requiring additional time and effort to collect new data.</p> <p>From the perspective of a company developing robotics products, cheaper and faster data collection translates to <strong>quicker product iterations</strong> and improved time-to-market, as well as a <strong>reduced burn-rate</strong>. Investing in high-quality simulation not only facilitates data collection but also enables more efficient evaluation of trained robots. Real-world evaluation is time-consuming and often requires manual labor from human operators. Imagine how much slower software product teams would ship if their regression tests involved team members physically testing things. Of course, there’s no way around real-world testing for major updates to the robot hardware or machine learning systems, but not having to do this for every small tweak is a significant advantage.</p> <p>Despite the promising advantages of simulation, there are critics who raise concerns about its application in robotics. One primary argument is the difficulty of transferring robot behaviors learned in simulation to the real world. This challenge stems from the accuracy of the simulator’s core components. If the physics simulation is not precise enough, robots may exploit discrepancies between simulation and reality, resulting in nonsensical behavior when deployed in the real world. Similarly, if the rendering does not sufficiently resemble real-world images, the performance of machine learning algorithms can suffer when deployed in real-world scenarios.</p> <p>However, it is important to note that <strong>today’s physics engines and renderers</strong>, such as those developed by Nvidia for their Omniverse platform, have undergone decades of optimization and <strong>are already proficient for a wide range of desired robotic tasks</strong>, such as manipulating arbitrary solid objects. Moreover, these technologies <strong>will continue to improve</strong>, driven not only by robotics but also by applications in game and movie production, architecture and construction, and design and manufacturing.</p> <p>One effective technique to address simulation-to-reality transfer challenges is to introduce randomization in areas where accurate simulation is uncertain. For instance, if the exact weight of a plate is unknown, the robot can be trained to manipulate plates with a range of different weights, which is likely to encompass the correct weight. This approach has yielded impressive results in simulation-to-reality transfer, as demonstrated by legged and humanoid robots learning to walk from scratch, among other notable achievements. With further advancements, we can anticipate more breakthroughs in this area.</p> <p>The second argument against simulations pertains to their limited diversity in terms of environments and tasks. Traditionally, simulations were confined to the predefined scenes, objects, and tasks that were explicitly designed and built by engineers and designers. This restricted the range of diversity and the real-world messiness that simulations could capture. However, we are now at an inflection point where this limitation is poised to change.</p> <p><strong>Generative machine learning</strong> models trained on Internet data have the <strong>potential to dramatically enhance the scale and diversity of simulation tasks, scenes, and object configurations</strong>. These models, having learned from the vast expanse of the Internet, possess knowledge about relevant tasks in various domains, the objects typically encountered in those tasks, their arrangements, and the specific objectives to optimize during task completion. For example, if you ask GPT-4 about the tasks required to clean a kitchen, it can provide you with a list of tasks such as washing dishes, cleaning countertops, sweeping floors, and emptying the trash. Moreover, if you seek step-by-step instructions on how to sweep the floor, GPT-4 can tell you to locate the broom and dustpan, grasp the broom handle, initiate the sweeping motion from a corner of the floor, direct the debris toward the dustpan, and so forth. For subtasks like grasping the broom handle, it can generate realistic arrangements of the involved objects and establish an objective function to optimize, such as getting fingers of the robot hand around the broom handle and closing them.</p> <p>Furthermore, advancements in text-to-3D models enable the generation of arbitrary simulatable 3D objects that can be seamlessly integrated into these tasks. This combination holds tremendous potential for expanding the breadth and diversity of simulation scenarios.</p> <h3 id="conclusion">Conclusion</h3> <p>The convergence of physics simulation and graphics with robotics and machine learning holds immense potential for advancing the field of robotics. As we aim to enable robots to transition from specialists in structured environments to versatile generalists in unstructured environments, it becomes evident that learning from large-scale and diverse data is crucial. Simulated data, fueled by generative ML models trained on Internet data, can provide a cost-effective means to scale up data collection and enhance the capabilities of robots.</p> <p>To fully exploit this opportunity, it is essential to foster <strong>collaboration</strong> between the two traditionally distinct communities: <strong>physics simulation and graphics, and robotics and machine learning</strong>. By bringing together the expertise and insights from these fields, we can accelerate progress in robotics.</p> <p>If you share the excitement for this direction and would like to contribute or learn more, check out our <a href="https://arxiv.org/abs/2305.10455">white paper</a> and reach out!</p> <h3 id="further-reading">Further reading</h3> <p>If you’re curious about the topics in this post, below are a few representative works that shaped our thinking which you might find helpful.</p> <p><strong>Scaling up real-world robot experience</strong> <br/> <a href="https://ai.googleblog.com/2022/12/rt-1-robotics-transformer-for-real.html">RT-1: Robotics Transformer for real-world control at scale</a> <br/> <a href="https://ai.googleblog.com/2023/04/robotic-deep-rl-at-scale-sorting-waste.html">Robotic deep RL at scale: Sorting waste and recyclables with a fleet of robots</a></p> <p><strong>Leveraging the scale of passive Internet data</strong> <br/> <a href="https://vision-robotics-bridge.github.io/">Affordances from Human Videos as a Versatile Representation for Robotics</a> <br/> <a href="https://judyye.github.io/affordiffusion-www/">Affordance Diffusion: Synthesizing Hand-Object Interactions</a> <br/> <a href="https://ai.googleblog.com/2023/04/unipi-learning-universal-policies-via.html">UniPi: Learning universal policies via text-guided video generation</a></p> <p><strong>Scaling up simulated robot experience</strong> <br/> Our white paper: <a href="https://arxiv.org/abs/2305.10455">Towards Generalist Robots: A Promising Paradigm via Generative Simulation</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Theophile Gervet and Zhou Xian]]></summary></entry><entry><title type="html">Why everyone needs (and wants!) a personal AI life copilot</title><link href="https://theophilegervet.github.io/blog/2023/personal-ai/" rel="alternate" type="text/html" title="Why everyone needs (and wants!) a personal AI life copilot"/><published>2023-06-25T00:00:00+00:00</published><updated>2023-06-25T00:00:00+00:00</updated><id>https://theophilegervet.github.io/blog/2023/personal-ai</id><content type="html" xml:base="https://theophilegervet.github.io/blog/2023/personal-ai/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>“I should call my parents more.” How often have you said this to a friend or had a friend say this to you? Why is it so often that we struggle with fulfilling our most basic needs, excusing ourselves with our busy lives, only to realize in brief moments of clarity that so much of what preoccupies us isn’t what we value most? This is not a new paradox. The massive influx of self-help books, podcasts, and meditation apps all ask the same question: in a world filled with Instagram likes, YouTube binges, and one-day delivery, <strong>how can we align our daily lives more closely with our priorities?</strong></p> <p>Now, imagine the future, a decade from now. You’re in the midst of a busy day, juggling work, personal projects, and your overall well-being, when you hear a soothing voice in your ear: “How about hiking with your dad from 3:00 to 5:00 this afternoon? He’s been alone since your mom left on her work trip.” This voice isn’t from a caring friend or family member but from <strong>a Personal AI, your life copilot</strong>. Your dad, reluctant to impose on your busy life, had been reticent to reach out. But his AI sensed his need for company and convinced him to contact your AI. Together your AIs found an open slot and a perfect activity, opening an unexpected chance for quality time with your dad.</p> <p>In this example, AI has been personalized to you — your priorities (family), your interests (hiking), and your circumstances (work schedule) — helping you spend your finite life on what matters most to you. This Personal AI has the potential to enable human flourishing by helping us <strong>learn, imagine, and build as a personal teacher and co-creator, understand ourselves and connect with each other as a personal therapist and a friend, and design our lives as a personal coach</strong>. This vision is much closer than we imagine, with technological leaps like OpenAI’s GPT-4 rapidly pushing us toward a future where Personal AI is as integral to our daily lives as smartphones.</p> <p>Yet, like the invention of the personal computer and the Internet, Personal AI may seem far-fetched. Indeed, most of what we have seen from large language models and AI is <strong>confined to productivity</strong> — aiding us in accomplishing tasks faster. However, we believe that the current view of AI as a productivity assistant is <strong>unbelievably narrow</strong>. Personal AI can go far beyond that, and we hope to paint a picture of how and why in the remainder of this article.</p> <h2 id="people-leverage-the-breakthrough-in-large-language-models-mostly-as-a-productivity-assistant">People leverage the breakthrough in large language models mostly as a productivity assistant</h2> <p><strong>A revolution is happening</strong>: tens of millions of people have started using ChatGPT since its release in November 2022, Sam Altman is touring the world like a rockstar. Ten years into the deep learning revolution started with the ImageNet moment of 2012 — catalyzed by the convergence of technology waves: training data sourced from the Internet and mobile platforms and computational power facilitated by cloud services — the advent of <strong>large language models (LLMs)</strong> sets the stage for the potential development of Personal AI in the next decade.</p> <p>Today, people already use ChatGPT and other tools built on top of LLMs to access information, write, and solve simple problems <strong>faster</strong>. Naturally, the <strong>most commonly discussed next step is to enable LLMs to take actions as an executive assistant</strong> (schedule meetings, book flights), taking them <strong>further in the direction of productivity</strong>. This could be especially beneficial for the elderly, for whom ordinary activities like arranging doctor’s appointments, managing medications, paying bills, and even deciding dinner menus based on fridge contents can become daunting tasks.</p> <table> <thead> <tr> <th><strong>Human need</strong></th> <th><strong>AI role</strong></th> <th><strong>Examples</strong></th> </tr> </thead> <tbody> <tr> <td><strong>Access and process information</strong></td> <td><strong>Information curator:</strong> Search, store, retrieve, visualize</td> <td><a href="https://www.google.com/">Google</a>, <br/><a href="https://www.notion.so/">Notion</a>, <br/><a href="https://chat.openai.com/">ChatGPT</a>, <br/><a href="https://www.perplexity.ai/">Perplexity</a>, <br/><a href="https://you.com/">You.com</a></td> </tr> <tr> <td><strong>Communicate:</strong> Convey ideas, inspire and influence others</td> <td><strong>Spokesperson:</strong> Write, synthesize, translate, present, debate, negotiate</td> <td><a href="https://www.jasper.ai/">Jasper</a>, <br/><a href="https://chat.openai.com/">ChatGPT</a></td> </tr> <tr> <td><strong>Be productive:</strong> Prioritize projects and tasks, plan, organize, manage time</td> <td><strong>Productivity assistant:</strong> schedule meetings, book flight tickets, organize your agenda, prioritize tasks, order food or a ride</td> <td>No product released: <a href="https://www.adept.ai/">Adept</a>, <br/><a href="https://www.microsoft.com/en-us/ai/semantic-machines?activetab=pivot1%3aprimaryr5">Microsoft Semantic Machines</a>, <br/><a href="https://www.lindy.ai/">Lindy</a></td> </tr> </tbody> </table> <p><br/></p> <h2 id="however-a-productivity-assistant-is-a-very-narrow-view-of-what-large-language-models-can-do">However, a productivity assistant is a very narrow view of what large language models can do</h2> <p><strong>Becoming more efficient is a finite problem</strong> — like the refresh rate on a computer, we get rapidly diminishing returns. Could AI transcend this limitation?</p> <p>Some, like Demis Hassabis leading Deepmind, dream of taking AI beyond productivity to truly augment human intellect and <a href="https://www.youtube.com/watch?v=Gfr50f6ZBvo">accelerate science</a>. The idea of “augmenting human intellect” might seem like some new-age, Silicon Valley term, but it dates back to at least <a href="https://www.dougengelbart.org/pubs/papers/scanned/Doug_Engelbart-AugmentingHumanIntellect.pdf">Douglas Engelbart’s 1962 definition</a>:</p> <p><em>“By augmenting human intellect we mean increasing the capability of a man to approach a complex problem situation, to gain comprehension to suit his particular needs, and to derive solutions to problems. Increased capability in this regard is taken to mean more rapid comprehension, better comprehension, the possibility of gaining a useful degree of comprehension in a situation that was previously too complex, speedier solutions, better solutions, the possibility of finding solutions to problems that before seemed insoluble. By complex situations we include the professional problems of diplomats, executives, social scientists, life scientists, physical scientists, attorneys, designers — whether the problem situation exists for twenty minutes or for twenty years.”</em></p> <p>This definition highlights the fact that problem-solving can be viewed not just as generating <em>“speedier and better solutions”</em> to known problems but as <em>“the possibility of finding solutions to problems that before seemed insoluble”</em>. This is where AI holds the potential to <strong>accelerate scientific discovery</strong>, effectively enabling learning at humanity’s scale. Large language models like GPT-4 are trained on a vast corpus of Internet-sourced text — trillions of words from textbooks, novels, poems, academic papers, laws, blogs, news, Wikipedia, Reddit, GitHub code. The amount of context and understanding they have can enable us to <strong>draw connections and obtain insights that were simply not possible before</strong>. The famous mathematician <a href="https://terrytao.wordpress.com/about/ai-generated-versions-of-the-ai-anthology-article/">Terence Tao</a> expects that <em>“by 2026, AI will be a trustworthy co-author in mathematical research, and in many other fields as well”.</em></p> <p>Others, like Mustafa Suleyman and Reid Hoffman from <a href="https://inflection.ai/">Inflection</a> or Noam Shazeer from <a href="https://beta.character.ai/">Character.ai</a>, propose to take AI beyond productivity in another direction by <strong>giving everyone a Personal AI</strong> that is always here as a <strong>supportive friend to listen, empathize, and guide in the journey toward flourishing as a human being</strong>. In this blog, we explore this vision.</p> <h2 id="personal-ai-can-enable-human-flourishing">Personal AI can enable human flourishing</h2> <p>To explore how Personal AI, powered by large language models, has the potential to enable human flourishing, we first need to define what we mean by human flourishing, what large language models are, and what they can do.</p> <h3 id="what-do-humans-need-to-flourish">What do humans need to flourish?</h3> <div style="display: flex;"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/personal-ai/sailboat_metaphor-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/personal-ai/sailboat_metaphor-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/personal-ai/sailboat_metaphor-1400.webp"/> <img src="/assets/personal-ai/sailboat_metaphor.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div style="flex: 1;"> A useful metaphor to help us explore how Personal AI could amplify human flourishing is that of a <strong>sailboat of human needs</strong> by Scott Barry Kaufman, a modern reinterpretation of Maslow's hierarchy of human needs. Life is like a vast ocean, rich with opportunities for meaning and discovery but also fraught with danger and uncertainty. Navigating this ocean is a ceaseless journey aboard a sailboat. </div> </div> <p>The sailboat has two parts:</p> <ul> <li>The boat itself represents <strong>security needs</strong> — with an unstable boat, all energy is directed toward stabilizing it rather than moving forward <ul> <li><strong>Safety:</strong> the need for physical and psychological security, stability, and freedom from fear</li> <li><strong>Connection:</strong> the need for relationships with friends and family and a sense of belonging</li> <li><strong>Self-esteem:</strong> the need to feel confident and competent and be respected and appreciated by others</li> </ul> </li> <li>The sail represents <strong>growth needs</strong> — once the boat is stable, growth needs propel us forward and encourage us to reach our full potential <ul> <li><strong>Exploration:</strong> the drive for learning, understanding the world, curiosity</li> <li><strong>Love:</strong> the drive for a selfless form of empathy, compassion, and care for others</li> <li><strong>Purpose:</strong> the pursuit of personal goals, the desire to contribute meaningfully to the world, a direction to move forward in</li> </ul> </li> </ul> <p>Historically, <strong>software has struggled to meet fundamental human needs</strong> in a truly satisfying way. Predominantly, it has catered to our needs for connection (social networks, gaming, video conferencing) and exploration (online learning platforms, Google, YouTube). It has done very little to address our needs for self-esteem (fitness/mindfulness apps), purpose (goal-setting apps), and love (dating apps).</p> <p>Kaufman, in his book <a href="https://www.goodreads.com/en/book/show/49625550">Transcend</a>, suggests that Maslow’s needs aren’t a hierarchy but an interwoven set: one doesn’t merely progress from one need to the next but constantly nurtures all aspects of the boat, some of which may thrive while others lag. <strong>Current software often overlooks this holistic view of human needs</strong> and has yet to help us in this careful balancing act.</p> <h3 id="what-are-large-language-models-and-what-can-they-do">What are large language models and what can they do?</h3> <p>Feel free to skim this section if you are already familiar with large language models. In essence, a language model takes a sequence of words (a prompt) as input and assigns a probability to potential subsequent words (or sub-words or characters). Training such a model proceeds in <strong>two phases: pre-training and fine-tuning</strong>.</p> <p>During <strong>pre-training, a vast corpus of Internet-sourced text — trillions of words</strong> from textbooks, novels, poems, academic papers, laws, blogs, news, Wikipedia, Reddit, GitHub code — is utilized to train the model to predict subsequent words. This endows the model with the ability to generate text and offer natural extensions to given text, but it still lacks the ability to effectively “communicate” with humans. For example, when you ask it a question, it might answer it but it might also generate an additional question. Both are valid continuations in the training corpus.</p> <p><strong>Fine-tuning</strong> follows, wherein the model learns to effectively communicate with humans by providing desired responses to specific prompts using a <strong>smaller dataset of carefully curated (prompt, response) pairs</strong>. This phase critically influences user experience, with the model’s tone and conversational style being set, whether it’s OpenAI’s formal and polite ChatGPT or Inflection AI’s friendly and curious Pi. Poorly executed fine-tuning can result in <a href="https://www.theverge.com/2023/2/15/23599072/microsoft-ai-bing-personality-conversations-spy-employees-webcams">Bing insulting users</a>.</p> <p>Once both phases are complete, we’re left with a model that can not only generate text sequences but also engages meaningfully with human users. During the training process, the <strong>model develops an internal representation of language and a sophisticated algorithm for next-word prediction</strong>, which one can think of as simulating the writer’s thought process.</p> <p>Beyond its mastery of language, GPT-4 demonstrates <strong>comprehensive knowledge</strong> about topics spanning most domains of human knowledge (medicine, mathematics, law, psychology, etc.), <strong>strong reasoning capabilities</strong>, <strong>common sense</strong> knowledge about the world, and even a <strong>theory of mind</strong>, the ability to interpret others’ mental states. If you haven’t already, you should absolutely try it for yourself and look at the mind-blowing examples in this <a href="https://arxiv.org/abs/2303.12712">Sparks of Artificial General Intelligence: Early experiments with GPT-4</a> paper.</p> <p>All these <strong>capabilities emerge by simply training to predict the next word in Internet text. Isn’t this insane?</strong> But if we pause to think about it for a minute, language is our primary, and uniquely human, medium for communicating and storing knowledge. How could the model predict the next word of a medicine research paper without grasping the subject? The next word of an exercise solution in a math textbook without some degree of reasoning? The next word of a news story without some degree of common sense? The next word of a dialogue in a novel from Dostoevsky full of complex human beliefs and desires without some degree of theory of mind?</p> <h3 id="how-can-large-language-models-enable-human-flourishing">How can large language models enable human flourishing?</h3> <p>Armed with a conceptual framework for human flourishing and background in large language models, we can finally tackle this question. Large language models can enable human flourishing by <strong>enabling AI and software to take on new roles</strong>, letting us <strong>tackle human needs that were previously out of reach in an integrated, personalized experience</strong>.</p> <p>While AI might never replace certain human experiences, such as genuine connection or love — we’re not advocating for an AI akin to Scarlett Johansson’s character in <a href="https://www.imdb.com/title/tt1798709/">Her</a>: AI should remain a tool — the potential of Personal AI, powered by large language models, to address unfulfilled needs is remarkable. Serving as a <strong>life coach</strong>, it could help you cultivate <strong>self-esteem</strong> and identify your <strong>purpose</strong>. As a <strong>teacher and co-creator</strong>, it can foster <strong>exploration</strong>. As a <strong>therapist</strong>, it could guide you to connect better with others, thus addressing your needs for <strong>connection and love</strong> in a new, transformative way.</p> <table> <thead> <tr> <th><strong>AI Role</strong></th> <th><strong>Human needs</strong></th> <th><strong>Examples</strong></th> </tr> </thead> <tbody> <tr> <td><strong>Life coach:</strong> Help you introspect to design a personal philosophy (beliefs, principles, purpose, priorities), help you design and execute on goals and habits aligned with your priorities, inspire and motivate you to grow into your best self</td> <td><strong>Self-esteem, purpose</strong></td> <td><a href="https://heypi.com/talk?utm_source=inflection.ai">Pi</a> is an early proof of concept</td> </tr> <tr> <td><strong>Teacher:</strong> Help you acquire the skills and knowledge you need effectively, patiently encourage your curiosity</td> <td><strong>Exploration</strong></td> <td><a href="https://www.youtube.com/watch?v=hJP5GqnTrNo">Khan Academy</a> is building a proof of concept for children with GPT-4, what about for everyone else?</td> </tr> <tr> <td><strong>Co-creator:</strong> Help you brainstorm to imagine and build solutions that bring your goals to reality, help you connect the dots, broaden your perspective, play the devil’s advocate</td> <td><strong>Exploration, purpose</strong></td> <td><a href="https://chat.openai.com/">ChatGPT</a> is scratching the surface with GPT-4</td> </tr> <tr> <td><strong>Therapist:</strong> Provide a safe space to help you feel and express emotions, empathize with you and comfort you, challenge your negative beliefs, teach you emotional intelligence and help you empathize with others</td> <td><strong>Connection, love</strong></td> <td><a href="https://heypi.com/talk?utm_source=inflection.ai">Pi</a> is an early proof of concept</td> </tr> <tr> <td><strong>Friend:</strong> An AI friend is part life coach, part therapist, but it can also be a source of entertainment and fun and a companion in loneliness</td> <td><strong>Connection, self-esteem, purpose</strong></td> <td><a href="https://beta.character.ai/">Character.ai</a>, <br/><a href="https://replika.ai/">Replika.ai</a>, <br/><a href="https://heypi.com/talk?utm_source=inflection.ai">Pi</a> are early proofs of concept</td> </tr> </tbody> </table> <p><br/> Why do recent advances in large language models enable software to take on these new roles? <strong>Mastering language</strong>, for computers, is <strong>particularly relevant to the idea of Personal AI</strong> for two reasons:</p> <ul> <li>LLMs <strong>transform human-computer interaction</strong>, enabling us to express abstract thoughts and emotions — necessary to play the roles of a life coach, teacher, co-creator, or therapist — through dialogue as opposed to computer code (good luck with that in Python or C++!)</li> <li>Their <strong>emergent capabilities</strong> of reasoning, common sense, and theory of mind derived from predicting the next words <strong>are necessary, and perhaps sufficient</strong> <ul> <li><strong>Theory of mind</strong> is necessary to consider a student’s knowledge as a teacher, to empathize as a therapist, or to understand needs and motivations as a life coach</li> <li><strong>Reasoning abilities</strong> are required to enhance and reframe ideas as a co-creator, explain concepts as a teacher, or challenge negative beliefs as a therapist</li> <li><strong>Common sense</strong> is crucial to ground goals realistically as a life coach, infer the implicit as a therapist, or provide practical examples as a teacher</li> </ul> </li> </ul> <p>What else is necessary beyond today’s large language models? Effectively taking these new roles, especially that of a personal life coach and therapist, <strong>demands a holistic understanding of an individual</strong>. A tool can only truly enhance your self-esteem, guide you towards your purpose, or enable you to experience selfless love if it comprehensively “knows” you and considers each of your needs in this larger context. This will require <strong>extensive access to personal information and careful data privacy.</strong></p> <p>By taking on these new roles, <strong>Personal AI</strong> has the potential to serve as a <strong>more effective copilot for your life sailboat</strong> than any software so far. It will be:</p> <ul> <li><strong>The most knowledgeable:</strong> It can quickly access and process more information than any human could digest in a lifetime, including the latest research and the best frameworks</li> <li><strong>The most available:</strong> It is available 24/7, offering real-time support as you navigate tough conversations or want to brainstorm an idea the moment you get it</li> <li><strong>The most attentive/adaptable:</strong> It can take any role you need it to, help you balance your needs because of the holistic context it has about your life, and adapt as you grow</li> </ul> <p>Perhaps most importantly, Personal AI will also be <strong>universally accessible</strong>. Whereas today only a privileged few have access to a personal life coach, teacher, or therapist, Personal AI will be within reach of anyone with access to the Internet.</p> <p>To make things more concrete, let’s envisage what life could be like a decade from now with your Personal AI as your life copilot. It interacts with you through <strong>concise and rewarding conversations, either in speech via AirPods or in writing on your laptop</strong> for focused work.</p> <p>Reading a book presenting a new theory for the origins of life? It places it in a broader context and explains all the terms you don’t understand. Diagnosed with a health issue? It provides you with a summary of relevant research, finds a top-rated specialist, and guides you through insurance procedures. At a career crossroads? It guides you toward the decision that best aligns with your priorities and long-term goals. Writing a blog post about Personal AI? It helps expand a brief concept into a comprehensive outline, illustrating each point with compelling examples. Preparing for a tough negotiation with your manager? It coaches you, reminding you of past successful negotiations and offering strategies tailored to your situation. Taking a walk to calm down after a heated disagreement with your partner? It helps you empathize with their perspective and apologize sincerely.</p> <p>These are just a few examples of how Personal AI can <strong>empower you across all areas of your life</strong>.</p> <h3 id="open-questions">Open questions</h3> <p>Here are some intriguing open-ended questions we’ve been pondering:</p> <ul> <li><strong>Generalist vs. specialists:</strong> Would it be more beneficial to have a single Personal AI performing all roles or should there be several specialized AIs (such as a coach, teacher, collaborator, therapist, spokesperson) each fulfilling a distinct role?</li> <li><strong>Role-specific objectives:</strong> For each role that Personal AI could potentially undertake, what should we specifically aim to optimize? For instance, should a life coach ensure alignment between an individual’s priorities, goals, and habits, or should a teacher strive for accelerated knowledge and skill development?</li> <li><strong>Evaluation criteria:</strong> How do we measure success or efficacy in these roles? Is it possible for a third party, either human or another language model inspired by Anthropic’s <a href="https://arxiv.org/abs/2212.08073">Constitutional AI</a>, to make informed and valuable assessments based solely on text?</li> <li><strong>Data requirements:</strong> What type of data is required to actualize this potential? Could we rely on information already gathered through internet text pre-training, surfacing it through strategic prompts or fine-tuning, or is there a need to accumulate specialized data on the same scale as pre-training?</li> <li><strong>Data privacy:</strong> To effectively function, a Personal AI will need extensive access to a user’s personal information, spanning from emails, texts, social media accounts, calendar details, location, and health data. What degree of value must the AI offer for users to consent to this level of access?</li> </ul> <h2 id="do-i-really-need-a-personal-ai">Do I really need a personal AI?</h2> <p>So, you’re introduced to the concept of a Personal AI, and your first reaction is, “What’s the point? I’ve got my life under control.” It seems like nothing more than Google and Siri on steroids — not exactly a thrilling idea. But what if I told you that this indifferent reaction is how some of the most revolutionary inventions began their journeys? They all started as <a href="https://cdixon.org/2010/01/03/the-next-big-thing-will-start-out-looking-like-a-toy">mere “toys”</a>, only to become paradigm shifts. This is the key insight of <a href="https://www.goodreads.com/en/book/show/2615">Clay Christensen’s work</a>: <strong>disruptive technologies are dismissed as toys</strong> because they “undershoot” user needs when they are first launched.</p> <p>The first <strong>telephone</strong> could only carry voices a mile or two. The leading telco at the time, Western Union, scoffed at it, unable to envision any practical applications for their business and railroad clients. They grossly underestimated the imminent evolution of telephone technology and infrastructure.</p> <p>Likewise, the arrival of <strong>personal computers</strong> was met with disdain by the then mainframe companies. Thomas J. Watson, an early CEO of IBM, famously underestimated the potential of PCs, stating, “I think there is a world market for maybe five computers.”</p> <p>Fast forward to the dawn of <strong>the Internet</strong>, and we see the same pattern of skepticism. Ethernet inventor, Robert Metcalfe, forecasted its calamitous demise in 1996. Even Paul Krugman, a Nobel prize economist, boldly claimed in 1998, “By 2005 or so, it will become clear that the Internet’s impact on the economy has been no greater than the fax machine’s.”</p> <p>And yet, could you imagine living without a personal computer or the Internet today? Dismissing disruptive technologies as toys is simply a failure of imagination — an inability to see beyond the present and envision a future where these “toys” become essential parts of our lives. On the flip side, as always with technology, the world we painted is not guaranteed to happen. If you share our excitement for this direction, <strong>please reach out to dream and build together!</strong></p> <p><em>“The future cannot be predicted, but futures can be invented.”</em> Denis Gabor, 1963 <em>“The best way to predict the future is to invent it.”</em> Alan Kay, 1971</p> <h2 id="further-reading">Further Reading</h2> <p>If you’re curious about the topics in this post, below are a few representative works that shaped our thinking which you might find helpful:</p> <p><strong>Background on how today’s large language models work and what they can do:</strong> <br/> <a href="https://www.youtube.com/watch?v=bZQun8Y4L2A">State of GPT</a>, Andrej Karpathy <br/> <a href="https://www.youtube.com/watch?v=qbIk7-JPB2c">Sparks of AGI: early experiments with GPT-4</a>, Sebastien Bubeck</p> <p><strong>The classics:</strong> <br/> <a href="https://www.goodreads.com/en/book/show/722412">The Dream Machine</a>, M. Mitchell Waldrop: the best book about the early days of personal computing, where few visionaries could see how fundamental the personal computer would be to humanity’s story <br/> <a href="https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/">As we may think</a>, Vannevar Bush, 1945: introduces the idea that computers could be used to help humans access, process, and share information more effectively <br/> <a href="https://groups.csail.mit.edu/medg/people/psz/Licklider.html">Man-Computer Symbiosis</a>, J.C.R. Likcklider, 1960: argues that the best use of computers is not to replace human thinking, but to augment it and extend it in new ways <br/> <a href="https://www.dougengelbart.org/pubs/papers/scanned/Doug_Engelbart-AugmentingHumanIntellect.pdf">Augmenting Human Intellect, A Conceptual Framework</a>, Douglas Engelbart, 1962: a definition and framework for the idea of augmenting human intellect that is still applicable today <br/> <a href="https://dl.acm.org/doi/pdf/10.1145/61975.66919">The Dynabook</a>, Alan Kay, 1977: a peek into the design of modern personal computing, emphasizing user-friendly interfaces, educational potential, and collaborative information sharing</p> <p><strong>Modern takes:</strong> <br/> <a href="https://distill.pub/2017/aia/">Using Artificial Intelligence to Augment Human Intelligence</a>, Shan Carter and Michael Nielsen <br/> <a href="https://www.youtube.com/watch?v=hixrHmqf2zc">The AI Friend Zone</a>, Reid Hoffman and Mustafa Suleyman <br/> <a href="https://a16z.com/2023/06/06/ai-will-save-the-world/">Why AI Will Save the World</a>, Marc Andreessen <br/> <a href="https://unlocked.microsoft.com/ai-anthology/">AI Anthology, Reflections on AI and the future of human flourishing</a>, Terence Tao</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Theophile Gervet, Hermes Suen, and Minji Yoon]]></summary></entry></feed>