<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script src="http://www.google.com/jsapi" type="text/javascript"></script> <script type="text/javascript">google.load("jquery","1.3.2");</script> <style type="text/css">body{font-family:"Titillium Web","HelveticaNeue-Light","Helvetica Neue Light","Helvetica Neue",Helvetica,Arial,"Lucida Grande",sans-serif;font-weight:300;font-size:18px;margin-left:auto;margin-right:auto;width:1100px}h1{font-weight:300}.disclaimerbox{background-color:#eee;border:1px solid #eee;border-radius:10px;-moz-border-radius:10px;-webkit-border-radius:10px;padding:20px}video.header-vid{height:140px;border:1px solid black;border-radius:10px;-moz-border-radius:10px;-webkit-border-radius:10px}img.header-img{height:140px;border:1px solid black;border-radius:10px;-moz-border-radius:10px;-webkit-border-radius:10px}img.rounded{border:1px solid #eee;border-radius:10px;-moz-border-radius:10px;-webkit-border-radius:10px}a:link,a:visited{color:#1367a7;text-decoration:none}a:hover{color:#208799}td.dl-link{height:160px;text-align:center;font-size:22px}.layered-paper-big{box-shadow:0 0 1px 1px rgba(0,0,0,0.35),5px 5px 0 0px #fff,5px 5px 1px 1px rgba(0,0,0,0.35),10px 10px 0 0px #fff,10px 10px 1px 1px rgba(0,0,0,0.35),15px 15px 0 0px #fff,15px 15px 1px 1px rgba(0,0,0,0.35),20px 20px 0 0px #fff,20px 20px 1px 1px rgba(0,0,0,0.35),25px 25px 0 0px #fff,25px 25px 1px 1px rgba(0,0,0,0.35);margin-left:10px;margin-right:45px}.layered-paper{box-shadow:0 0 1px 1px rgba(0,0,0,0.35),5px 5px 0 0px #fff,5px 5px 1px 1px rgba(0,0,0,0.35),10px 10px 0 0px #fff,10px 10px 1px 1px rgba(0,0,0,0.35);margin-top:5px;margin-left:10px;margin-right:30px;margin-bottom:5px}.vert-cent{position:relative;top:50%;transform:translateY(-50%)}hr{border:0;height:1px;background-image:linear-gradient(to right,rgba(0,0,0,0),rgba(0,0,0,0.75),rgba(0,0,0,0))}#authors td{padding-bottom:5px;padding-top:30px}</style> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-114291442-6"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-114291442-6");</script> <script type="text/javascript" src="resources/hidebib.js"></script> <link href="https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic" rel="stylesheet" type="text/css"> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <link rel="icon" type="image/png" href="../img/favicon.ico"> <title>Navigating to Objects in the Real World</title> <meta name="HandheldFriendly" content="True"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <script src="https://www.youtube.com/iframe_api"></script> </head> <body> <br> <center><span style="font-size:44px;font-weight:bold;">Navigating to Objects in the Real World</span></center> <br> <table align="center" width="600px"> <tr> <td align="center" width="100px"> <center><span style="font-size:22px"><a href="https://theophilegervet.github.io/" target="_blank">Theophile Gervet</a></span></center> </td> <td align="center" width="100px"> <center><span style="font-size:22px"><a href="https://soumith.ch/" target="_blank" rel="external nofollow noopener">Soumith Chintala</a></span></center> </td> <td align="center" width="100px"> <center><span style="font-size:22px"><a href="https://faculty.cc.gatech.edu/~dbatra/" target="_blank" rel="external nofollow noopener">Dhruv Batra</a></span></center> </td> <td align="center" width="100px"> <center><span style="font-size:22px"><a href="https://people.eecs.berkeley.edu/~malik/" target="_blank" rel="external nofollow noopener">Jitendra Malik</a></span></center> </td> <td align="center" width="160px"> <center><span style="font-size:22px"><a href="https://devendrachaplot.github.io/" target="_blank" rel="external nofollow noopener">Devendra Singh Chaplot</a></span></center> </td> </tr> <tr></tr> <tr> <td align="center" width="100px"> <center><span style="font-size:20px">CMU</span></center> </td> <td align="center" width="100px"> <center><span style="font-size:20px">FAIR</span></center> </td> <td align="center" width="100px"> <center><span style="font-size:20px">FAIR</span></center> </td> <td align="center" width="100px"> <center><span style="font-size:20px">FAIR</span></center> </td> <td align="center" width="100px"> <center><span style="font-size:20px">FAIR</span></center> </td> </tr> <tr></tr> </table> <table align="center" width="700px"> <tr> <td align="center" width="100px"><center><span style="font-size:28px"><a href="https://arxiv.org/abs/2212.00922" rel="external nofollow noopener" target="_blank">[Arxiv]</a></span></center></td> <td align="center" width="100px"><center><span style="font-size:28px"><a href="https://www.science.org/doi/10.1126/scirobotics.adf6991" rel="external nofollow noopener" target="_blank">[Science Robotics]</a></span></center></td> <td align="center" width="100px"><center><span style="font-size:28px"><a href="https://github.com/facebookresearch/home-robot/" rel="external nofollow noopener" target="_blank">[Code]</a></span></center></td> <td align="center" width="100px"><center><span style="font-size:28px"><a href="https://www.youtube.com/embed/zZ6nlkTZVds" rel="external nofollow noopener" target="_blank">[Talk]</a></span></center></td> <td align="center" width="100px"><center><span style="font-size:28px"><a href="../../slides/real-world-object-navigation.pdf">[Slides]</a></span></center></td> </tr> <tr></tr> </table> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/summary.gif"><img src="../../assets/real-world-object-navigation/summary.gif" width="800px"></a><br> </center> </td></tr> </table> <br> <div style="width:800px; margin:0 auto; text-align:justify"> Semantic navigation is necessary to deploy mobile robots in uncontrolled environments like our homes, schools, and hospitals. Many learning-based approaches have been proposed in response to the lack of semantic understanding of the classical pipeline for spatial navigation. But learned visual navigation policies have predominantly been evaluated in simulation. How well do different classes of methods work on a robot? We present a large-scale empirical study of semantic visual navigation methods comparing representative methods from classical, modular, and end-to-end learning approaches across six homes with no prior experience, maps, or instrumentation. We find that modular learning works well in the real world, attaining a 90% success rate. In contrast, end-to-end learning does not, dropping from 77% simulation to 23% real-world success rate due to a large image domain gap between simulation and reality. For practitioners, we show that modular learning is a reliable approach to navigate to objects: modularity and abstraction in policy design enable Sim-to-Real transfer. For researchers, we identify two key issues that prevent today's simulators from being reliable evaluation benchmarks — (A) a large Sim-to-Real gap in images and (B) a disconnect between simulation and real-world error modes — and propose concrete steps forward. </div> <br><hr> <center><h1>Object Goal Navigation</h1></center> <div style="width:800px; margin:0 auto; text-align:justify"> We instantiate semantic navigation with the Object Goal navigation task, where a robot starts in a completely unseen environment and is asked to find an instance of an object category, let's say a toilet. The robot has access to only a first-person RGB and depth camera and a pose sensor. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1200px"> <center><a href="../../assets/real-world-object-navigation/objectnav_problem.png"><img src="../../assets/real-world-object-navigation/objectnav_problem.png" width="800px"></a></center> </td></tr> </table> <br> <div style="width:800px; margin:0 auto; text-align:justify"> This task is challenging. The robot requires not only spatial scene understanding of distinguishing free space and obstacles and semantic scene understanding of detecting objects, but also requires learning semantic exploration priors. For example, if a human wants to find a toilet in this scene, most of us would choose the hallway because it is most likely to lead to a toilet. Teaching this kind of common sense or semantic priors to an autonomous agent is challenging. While exploring the scene for the desired object, the robot also needs a long-term episodic memory to remember explored and unexplored areas. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1200px"> <center> <a href="../../assets/real-world-object-navigation/challenging_problem.png"><img src="../../assets/real-world-object-navigation/challenging_problem.png" width="800px"></a><br> </center> </td></tr> </table> <br><hr> <center><h1>Methods</h1></center> <div style="width:800px; margin:0 auto; text-align:justify"> So how do we train autonomous agents capable of efficient navigation while tackling all these challenges? A classical approach to this problem builds a geometric map using depth sensors, explores the environment with a heuristic, like frontier exploration, which explores the closest unexplored region, and uses an analytical planner to reach exploration goals and the goal object as soon as it is in sight. An end-to-end learning approach predicts actions directly from raw observations with a deep neural network consisting of visual encoders for image frames followed by a recurrent layer for memory. A modular learning approach builds a semantic map by projecting predicted semantic segmentation using depth, predicts an exploration goal with a goal-oriented semantic policy as a function of the semantic map and the goal object, and reaches it with a planner. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1200px"> <center> <a href="../../assets/real-world-object-navigation/methods.gif"><img src="../../assets/real-world-object-navigation/methods.gif" width="800px"></a><br> </center> </td></tr> </table> <br><hr> <center><h1>Large-scale Real-world Empirical Evaluation</h1></center> <div style="width:800px; margin:0 auto; text-align:justify"> While many approaches to navigate to objects have been proposed over the past few years, learned navigation policies have predominantly been evaluated in simulation, which opens the field to the risk of sim-only research that does not generalize to the real world. We address this issue through a large-scale empirical evaluation of representative classical, end-to-end learning, and modular learning approaches across 6 unseen homes and 6 goal object categories. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/empirical_evaluation.gif"><img src="../../assets/real-world-object-navigation/empirical_evaluation.gif" width="800px"></a><br> </center> </td></tr> </table> <br><hr> <center><h1>Results</h1></center> <div style="width:800px; margin:0 auto; text-align:justify"> We compare approaches in terms of success rate within a limited budget of 200 robot actions and Success weighted by Path Length (SPL), a measure of path efficiency. In simulation, all approaches perform comparably, at around 80% success rate. But in the real world, modular learning and classical approaches transfer really well, up from 81% to 90% and 78% to 80% success rates, respectively. While end-to-end learning fails to transfer, down from 77% to 23% success rate. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/results_quantitative.png"><img src="../../assets/real-world-object-navigation/results_quantitative.png" width="800px"></a><br> </center> </td></tr> </table> <br> <div style="width:800px; margin:0 auto; text-align:justify"> We illustrate these results qualitatively with one representative trajectory. All approaches start in a bedroom and are tasked with finding a couch. On the left, modular learning first successfully reaches the couch goal. In the middle, end-to-end learning fails after colliding too many times. On the right, the classical policy finally reaches the couch goal after a detour through the kitchen. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/results_qualitative.gif"><img src="../../assets/real-world-object-navigation/results_qualitative.gif" width="800px"></a><br> </center> </td></tr> </table> <center><h2>Result 1: Modular Learning is Reliable</h2></center> <div style="width:800px; margin:0 auto; text-align:justify"> We find that modular learning is very reliable on a robot, with a 90% success rate. Here, we can see it finds a plant in a first home efficiently, a chair in a second home, and a toilet in a third. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/modular_reliability.gif"><img src="../../assets/real-world-object-navigation/modular_reliability.gif" width="800px"></a><br> </center> </td></tr> </table> <center><h2>Result 2: Modular Learning Explores more Efficiently than Classical</h2></center> <div style="width:800px; margin:0 auto; text-align:justify"> Modular learning improves by 10% real-world success rate over the classical approach. On the left, the goal-oriented semantic exploration policy directly heads towards the bedroom and finds the bed in 98 steps with an SPL of 0.90. On the right, because frontier exploration is agnostic to the bed goal, the policy makes detours through the kitchen and the entrance hallway before finally reaching the bed in 152 steps with an SPL of 0.52. With a limited time budget, inefficient exploration can lead to failure. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/modular_vs_classical.gif"><img src="../../assets/real-world-object-navigation/modular_vs_classical.gif" width="800px"></a><br> </center> </td></tr> </table> <center><h2>Result 3: End-to-end Learning Fails to Transfer</h2></center> <div style="width:800px; margin:0 auto; text-align:justify"> While classical and modular learning approaches work well on a robot, end-to-end learning does not, at only 23% success rate. The policy collides often, revisits the same places, and even fails to stop in front of goal objects when they are in sight. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/end_to_end_failures.gif"><img src="../../assets/real-world-object-navigation/end_to_end_failures.gif" width="800px"></a><br> </center> </td></tr> </table> <br><hr> <center><h1>Analysis</h1></center> <center><h2>Insight 1: Why does Modular Transfer while End-to-end does not?</h2></center> <div style="width:800px; margin:0 auto; text-align:justify"> Why does modular learning transfer so well while end-to-end learning does not? To answer this question, we reconstructed one real-world home in simulation and conducted experiments with identical episodes in sim and reality. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/reconstruction.gif"><img src="../../assets/real-world-object-navigation/reconstruction.gif" width="800px"></a><br> </center> </td></tr> </table> <br> <div style="width:800px; margin:0 auto; text-align:justify"> The semantic exploration policy of the modular learning approach takes a semantic map as input, while the end-to-end policy directly operates on the RGB-D frames. The semantic map space is invariant between sim and reality, while the image space exhibits a large domain gap. In this example, this gap leads to a segmentation model trained on real-world images to predict a bed false positive in the kitchen. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/sim_vs_real_episode.gif"><img src="../../assets/real-world-object-navigation/sim_vs_real_episode.gif" width="800px"></a><br> </center> </td></tr> </table> <br> <div style="width:800px; margin:0 auto; text-align:justify"> The semantic map domain invariance allows the modular learning approach to transfer well from sim to reality. In contrast, the image domain gap causes a large drop in performance when transferring a segmentation model trained in the real world to simulation and vice versa. If semantic segmentation transfers poorly from sim to reality, it is reasonable to expect an end-to-end semantic navigation policy trained on sim images to transfer poorly to real-world images. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/gaps_and_invariances.png"><img src="../../assets/real-world-object-navigation/gaps_and_invariances.png" width="800px"></a><br> </center> </td></tr> </table> <center><h2>Insight 2: Sim vs Real Gap in Error Modes for Modular Learning</h2></center> <div style="width:800px; margin:0 auto; text-align:justify"> Surprisingly, modular learning works even better in reality than simulation. Detailed analysis reveals that a lot of the failures of the modular learning policy that occur in sim are due to reconstruction errors, which do not happen in reality. Visual reconstruction errors represent 10% out of the total 19% episode failures, and physical reconstruction errors another 5%. In contrast, failures in the real world are predominantly due to depth sensor errors, while most semantic navigation benchmarks in simulation assume perfect depth sensing. Besides explaining the performance gap between sim and reality for modular learning, this gap in error modes is concerning because it limits the usefulness of simulation to diagnose bottlenecks and further improve policies. We show representative examples of each error mode and propose concrete steps forward to close this gap in the paper. </div> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/error_modes.png"><img src="../../assets/real-world-object-navigation/error_modes.png" width="800px"></a><br> </center> </td></tr> </table> <br><hr> <center><h1>Takeaways</h1></center> <table align="center" width="1000px"> <p style="margin-top:4px;"></p> <tr><td width="1000px"> <center> <a href="../../assets/real-world-object-navigation/takeaways.png"><img src="../../assets/real-world-object-navigation/takeaways.png" width="800px"></a><br> </center> </td></tr> </table> <br><hr> <center><h1>Short Presentation</h1></center> <table align="center" width="300px"> <tr><td align="center" width="300px"> <iframe width="800" height="450" src="https://www.youtube.com/embed/zZ6nlkTZVds" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </td></tr> </table> <br> <div style="width:800px; margin:0 auto; text-align:justify"> Voice by <a href="https://www.btrabucco.com/" target="_blank" rel="external nofollow noopener">Brandon Trabucco</a>. </div> <br><br> <script xml:space="preserve" language="JavaScript">hideallbibs();</script> </body> </html>